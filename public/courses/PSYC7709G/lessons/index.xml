<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course Lessons and Assignments | djshives</title>
    <link>https://djshives.netlify.app/courses/psyc7709g/lessons/</link>
      <atom:link href="https://djshives.netlify.app/courses/psyc7709g/lessons/index.xml" rel="self" type="application/rss+xml" />
    <description>Course Lessons and Assignments</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 31 Jan 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://djshives.netlify.app/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Course Lessons and Assignments</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/</link>
    </image>
    
    <item>
      <title>Lab 1 - Shaping Data</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-1-shaping-data/</link>
      <pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-1-shaping-data/</guid>
      <description>&lt;h2 id=&#34;loading-libraries&#34;&gt;Loading libraries.&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(readxl)
library(tidyxl)
library(unpivotr)
library(reshape2)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;loading-data&#34;&gt;Loading data.&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data = read_excel(&amp;quot;data/Lab1_data.xlsx&amp;quot;, col_names = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New names:
## * `` -&amp;gt; ...1
## * `` -&amp;gt; ...2
## * `` -&amp;gt; ...3
## * `` -&amp;gt; ...4
## * `` -&amp;gt; ...5
## * ...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;manipulating-data-into-long-format-using-unpivotr-and-tidyxl&#34;&gt;Manipulating data into long format using unpivotr and tidyxl.&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data2 &amp;lt;- data %&amp;gt;% 
  as_cells() %&amp;gt;%
  behead(&amp;quot;up-left&amp;quot;, noise_level) %&amp;gt;%
  behead(&amp;quot;up-left&amp;quot;, time_of_day) %&amp;gt;%
  behead(&amp;quot;up-left&amp;quot;, a_b) %&amp;gt;%
  filter(a_b != &amp;quot;Participant&amp;quot;) %&amp;gt;%
  rename(score = chr) %&amp;gt;%
  select(score, noise_level, time_of_day, a_b)

data2$participant &amp;lt;- rep(1:10, 12)

data2 &amp;lt;- data2 %&amp;gt;%
  relocate(participant, .before = score) %&amp;gt;%
  relocate(score, .after = a_b) %&amp;gt;%
  arrange(participant, decreasting = TRUE)

data2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 × 5
##    participant noise_level time_of_day a_b   score
##          &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
##  1           1 Noisy       Morning     A     61   
##  2           1 Noisy       Morning     B     77   
##  3           1 Noisy       Afternoon   A     97   
##  4           1 Noisy       Afternoon   B     97   
##  5           1 Noisy       Evening     A     89   
##  6           1 Noisy       Evening     B     94   
##  7           1 Quiet       Morning     A     87   
##  8           1 Quiet       Morning     B     87   
##  9           1 Quiet       Afternoon   A     65   
## 10           1 Quiet       Afternoon   B     53   
## # … with 110 more rows
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;manipulating-data-into-long-format-using-the-tidyverse&#34;&gt;Manipulating data into long format using the tidyverse.&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data_headerless &amp;lt;- data[-c(1, 2), ] %&amp;gt;%
  select(!1)

colnames(data_headerless) &amp;lt;- data_headerless[1, ]

data_headerless &amp;lt;- data_headerless[-1, ]

data_headerless$participant &amp;lt;- 1:10

data_headerless &amp;lt;- pivot_longer(data_headerless, cols = c(A, B))

data_headerless$time_of_day &amp;lt;- rep(c(rep(&amp;quot;Morning&amp;quot;, 2), rep(&amp;quot;Afternoon&amp;quot;, 2), rep(&amp;quot;Evening&amp;quot;, 2)), 20)

data_headerless$noise_level &amp;lt;- rep(c(rep(&amp;quot;Noisy&amp;quot;, 6), rep(&amp;quot;Quiet&amp;quot;, 6)), 10)

data_headerless
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 120 × 5
##    participant name  value time_of_day noise_level
##          &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;      
##  1           1 A     61    Morning     Noisy      
##  2           1 B     77    Morning     Noisy      
##  3           1 A     97    Afternoon   Noisy      
##  4           1 B     97    Afternoon   Noisy      
##  5           1 A     89    Evening     Noisy      
##  6           1 B     94    Evening     Noisy      
##  7           1 A     87    Morning     Quiet      
##  8           1 B     87    Morning     Quiet      
##  9           1 A     65    Afternoon   Quiet      
## 10           1 B     53    Afternoon   Quiet      
## # … with 110 more rows
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Lab 2 - Multiple Regression I</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-2-multiple-regression-i/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-2-multiple-regression-i/</guid>
      <description>&lt;h2 id=&#34;loading-libraries&#34;&gt;Loading libraries.&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(tidyverse)
library(ggrepel)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;original-graph&#34;&gt;Original Graph&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;slamecka_design &amp;lt;- tibble(number_of_learning_trials = rep(c(2,4,8), each=6),
                          number_of_IL = rep(rep(c(2,4,8), 2), 3),
                          subjects = 1:18,
                          recall = c(35,21,6,
                                   39,31,8,
                                   40,34,18,
                                   52,42,26,
                                   61,58,46,
                                   73,66,52
                                   )
                          )

ggplot(slamecka_design,aes(x=number_of_IL,
                           group = number_of_learning_trials,
                           y=recall))+
  geom_line(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;)+
  geom_point(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;)+
  
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab2_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;modified-graph-to-match-figure-55-in-the-textbook&#34;&gt;Modified graph to match Figure 5.5 in the textbook.&lt;/h2&gt;
&lt;p&gt;Modifications include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Changing the x-axis title.&lt;/li&gt;
&lt;li&gt;Changing the y-axis title.&lt;/li&gt;
&lt;li&gt;Making the x-axis and y-axis ticks the same as in the textbook.&lt;/li&gt;
&lt;li&gt;Including different symbols to differentiate the lines.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;labels = c(&amp;quot;2 learning trials&amp;quot;, &amp;quot;4 learning trials&amp;quot;, &amp;quot;8 learning trials&amp;quot;)

slamecka_design &amp;lt;- tibble(number_of_learning_trials = rep(c(2,4,8), each=6),
                          number_of_IL = rep(rep(c(2,4,8), 2), 3),
                          subjects = 1:18,
                          recall = c(35,21,6,
                                   39,31,8,
                                   40,34,18,
                                   52,42,26,
                                   61,58,46,
                                   73,66,52
                                   )
                          )

slamecka_design &amp;lt;- slamecka_design %&amp;gt;%
  mutate(
    label = case_when(
      (number_of_IL == 8 &amp;amp; subjects == 6) ~ &amp;quot;2 learning trials&amp;quot;,
      (number_of_IL == 8 &amp;amp; subjects == 12) ~ &amp;quot;4 learning trials&amp;quot;,
      (number_of_IL == 8 &amp;amp; subjects == 18) ~ &amp;quot;8 learning trials&amp;quot;
    )
  )
           
ggplot(slamecka_design,aes(x=number_of_IL,
                           group = number_of_learning_trials,
                           y=recall)) +
  geom_line(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;) +
  geom_text_repel(aes(label = label), nudge_x = 1, na.rm = TRUE) +
  geom_point(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;, aes(shape = factor(number_of_learning_trials)), show.legend = FALSE) +
  xlab(&amp;quot;Number of interpolated lists&amp;quot;) +
  ylab(&amp;quot;Number of words correct&amp;quot;) +
  scale_x_continuous(breaks = c(2, 4, 8),
                   labels = c(2, 4, 8)) +
  ylim(0, 80) +
  expand_limits(x = 9) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab2_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;3x3x3-design-and-graph&#34;&gt;3x3x3 Design and Graph&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;labels = c(&amp;quot;2 learning trials&amp;quot;, &amp;quot;4 learning trials&amp;quot;, &amp;quot;8 learning trials&amp;quot;)

slamecka_design2 &amp;lt;- tibble(number_of_learning_trials = rep(c(2,4,8), each=18),
                          number_of_IL = rep(rep(c(2,4,8), 2), 9),
                          reward = rep(c(rep(0, 6), rep(50, 6), rep(1000, 6)), 3),
                          subjects = 1:54,
                          recall = sample(1:100, 54, replace = TRUE)
                          )

slamecka_design2 &amp;lt;- slamecka_design2 %&amp;gt;%
  mutate(
    label = case_when(
      (number_of_IL == 8 &amp;amp; subjects == 6) ~ &amp;quot;2 learning trials&amp;quot;,
      (number_of_IL == 8 &amp;amp; subjects == 12) ~ &amp;quot;4 learning trials&amp;quot;,
      (number_of_IL == 8 &amp;amp; subjects == 18) ~ &amp;quot;8 learning trials&amp;quot;
    )
  )
           
ggplot(slamecka_design2,aes(x=number_of_IL,
                           group = number_of_learning_trials,
                           y=recall)) +
  facet_wrap(~reward) +
  geom_line(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;) +
  geom_point(stat = &amp;quot;summary&amp;quot;, fun = &amp;quot;mean&amp;quot;, aes(shape = factor(number_of_learning_trials))) +
  xlab(&amp;quot;Number of interpolated lists&amp;quot;) +
  ylab(&amp;quot;Number of words correct&amp;quot;) +
  theme(legend.title = element_text(size = 1), 
               legend.text = element_text(size = 1)) +
  labs(shape = &amp;quot;Number of learning trials&amp;quot;) +
  scale_x_continuous(breaks = c(2, 4, 8),
                   labels = c(2, 4, 8),
                   sec.axis = sec_axis(~ . , name = &amp;quot;Reward&amp;quot;, breaks = NULL, labels = NULL)) +
  ylim(0, 80) +
  expand_limits(x = 9) +
  theme_classic()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 11 rows containing non-finite values (stat_summary).
## Removed 11 rows containing non-finite values (stat_summary).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab2_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lab 3 - Multiple Regression II</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-3-multiple-regression-ii/</link>
      <pubDate>Fri, 04 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-3-multiple-regression-ii/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The mechanics of multivariate regression in R are relatively straightforward. By using the lm() function, building complex linear models is a quick and efficient affair.&lt;/p&gt;
&lt;h3 id=&#34;data-and-exploratory-data-analysis&#34;&gt;Data and Exploratory Data Analysis&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s begin by loading in the necessary packages&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(MASS)
library(tidyverse)
library(ggrepel)
library(extraDistr)
library(loo)
library(bridgesampling)
library(brms)
library(rstan)
library(bayesplot)
library(tictoc)
library(hypr)
library(tidybayes)
rstan_options(auto_write = FALSE)
options(mc.cores = parallel::detectCores())
select &amp;lt;- dplyr::select
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;hellip;And create a toy dataset. For this lab, we will be using the research design by Hulme et al. (1984) that investigates whether age and speech rate are involed with memory ability.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data &amp;lt;- tibble(age = c(4,4,7,7,10,10),
               speech_rate = c(1,2,2,4,3,6),
               memory = c(14,23,30,50,39,67),
               id = c(1, 2, 3, 4, 5, 6))

data
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 4
##     age speech_rate memory    id
##   &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     4           1     14     1
## 2     4           2     23     2
## 3     7           2     30     3
## 4     7           4     50     4
## 5    10           3     39     5
## 6    10           6     67     6
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see from the above as speech rate increases, so does memory ability. The same, however, can be said for age and memory ability. This can be better illustrated visually.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data %&amp;gt;%
  ggplot(aes(x = speech_rate, y = memory, group = age)) +
  geom_point() +
  facet_wrap(~age) +
  geom_label_repel(aes(label = memory), nudge_x = 1, na.rm = TRUE) +
  scale_x_continuous(
    limits = c(0, 7),
    sec.axis = sec_axis(~ . , name = &amp;quot;Age&amp;quot;, breaks = NULL, labels = NULL)
    ) +
  ggtitle(&amp;quot;Memory by Speech Rate&amp;quot;) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab3_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, it looks like we have an issue of independent variables being correlated with one another, known as multicollinearity.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   age speech_rate    memory        id
## age         1.0000000   0.7500000 0.8027961 0.9561829
## speech_rate 0.7500000   1.0000000 0.9889517 0.8964215
## memory      0.8027961   0.9889517 1.0000000 0.9261501
## id          0.9561829   0.8964215 0.9261501 1.0000000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see from the above, there is a 75% correlation between age and speech_rate. This means that a complete pooling regression model, where all of the data is pooled together, is not appropriate.&lt;/p&gt;
&lt;p&gt;We can build the complete pooling model using the lm() function. The dependent variable, memory, is placed to the left of the &amp;ldquo;~&amp;rdquo; in the function, and the independent variables, age and speech_rate, to the right. The &amp;ldquo;data&amp;rdquo; parameter is filled by data.&lt;/p&gt;
&lt;p&gt;The summary() function is then used to view the regression output.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;complete_pool &amp;lt;- lm(
  memory ~ 1 + speech_rate + age,
  data = data
  )

summary(complete_pool)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = memory ~ 1 + speech_rate + age, data = data)
## 
## Residuals:
##      1      2      3      4      5      6 
## -1.167 -1.667  2.333  3.333 -1.167 -1.667 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)   
## (Intercept)    1.667      3.598   0.463  0.67470   
## speech_rate    9.500      1.087   8.736  0.00316 **
## age            1.000      0.725   1.379  0.26162   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.877 on 3 degrees of freedom
## Multiple R-squared:  0.9866,	Adjusted R-squared:  0.9776 
## F-statistic: 110.1 on 2 and 3 DF,  p-value: 0.001559
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is a high R^2 for the model, but when looking at the individual r^2 for the independent variables&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor(data) ^ 2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   age speech_rate    memory        id
## age         1.0000000   0.5625000 0.6444815 0.9142857
## speech_rate 0.5625000   1.0000000 0.9780254 0.8035714
## memory      0.6444815   0.9780254 1.0000000 0.8577539
## id          0.9142857   0.8035714 0.8577539 1.0000000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;hellip;They sum to greater than 1!&lt;/p&gt;
&lt;p&gt;So what is to be done?&lt;/p&gt;
&lt;h2 id=&#34;no-pooling-models&#34;&gt;No Pooling Models&lt;/h2&gt;
&lt;p&gt;One possible solution is to not pool any data and create an individual model for each age bucket&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ggplot(
  data = data,
  aes(
    x = speech_rate,
    y = memory,
    col = age,
    group = age
  )
) +
  geom_point() +
  geom_smooth(
    method = lm
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &#39;y ~ x&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in qt((1 - level)/2, df): NaNs produced

## Warning in qt((1 - level)/2, df): NaNs produced

## Warning in qt((1 - level)/2, df): NaNs produced
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning
## -Inf

## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning
## -Inf

## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning
## -Inf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab3_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But this looses the relationship between speech rate and age. In large data sets, this can become especially confusing and time consuming.&lt;/p&gt;
&lt;h2 id=&#34;partial-pooling-model-multilevel&#34;&gt;Partial-Pooling Model: Multilevel&lt;/h2&gt;
&lt;p&gt;Rather than no pooling or complete pooling, we can create a partially-pooled multilevel model! Partial pooling is a process where population-level and individual-level effects are estimated simultaneously. By doing so, each individual&amp;rsquo;s estimated effect is a reflection of the weighted combination of their own data and the population average. This allows us to account for the relationship between speech rate and age.&lt;/p&gt;
&lt;p&gt;Using the brms package, we can easily fit a multilevel model in a very similar fashion to the lm() function. The dependent variable for the model again falls to the left of the &amp;ldquo;~&amp;rdquo; and the independent variables are placed to the right. What is different, however, is in the parentheses, &amp;ldquo;(speech_rate|age)&amp;rdquo;. What this parameter does is specify that we want varying slopes and intercepts for speech rate for each age grouping.&lt;/p&gt;
&lt;p&gt;(Aside: we also specify several other things unique to Bayesian models, most notably priors. Prior specification is a topic in it of itself, and for this model we can use vaguely informative priors based on the means and standard deviations of the data itself.)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;priors &amp;lt;- c(
  prior(normal(3, 2), class = b, coef = speech_rate),
  prior(normal(0, 2), class = Intercept),
  prior(normal(0, 2), class = sigma),
  prior(normal(0, 2), class = sd, coef = Intercept, group = age),
  prior(normal(3, 2), class = sd, coef = speech_rate, group = age)
)

partial_pool_model &amp;lt;- brm(
  memory ~ 1 + speech_rate + (speech_rate|age),
  data = data,
  prior= priors,
  iter = 4000,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
    )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similar to using the &amp;ldquo;summary()&amp;rdquo; function for the complete pooling model, we can use it here for the multilevel model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(partial_pool_model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: There were 278 divergent transitions after warmup. Increasing
## adapt_delta above 0.99 may help. See http://mc-stan.org/misc/
## warnings.html#divergent-transitions-after-warmup
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: memory ~ 1 + speech_rate + (speech_rate | age) 
##    Data: data (Number of observations: 6) 
##   Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup draws = 8000
## 
## Group-Level Effects: 
## ~age (Number of levels: 3) 
##                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## sd(Intercept)                  2.66      1.58     0.16     5.97 1.00     1534
## sd(speech_rate)                6.18      1.25     3.98     8.83 1.01      439
## cor(Intercept,speech_rate)     0.50      0.44    -0.70     0.99 1.01     1247
##                            Tail_ESS
## sd(Intercept)                  2288
## sd(speech_rate)                3105
## cor(Intercept,speech_rate)     1383
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept       3.67      3.53    -4.17     9.77 1.02     2575     4009
## speech_rate    -0.50      1.21    -2.67     2.03 1.02     2718     3747
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.69      1.03     0.17     4.19 1.03      137       33
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mcmc_areas(
  partial_pool_model,
  pars = c(
    &amp;quot;b_Intercept&amp;quot;,
    &amp;quot;b_speech_rate&amp;quot;,
    &amp;quot;sd_age__Intercept&amp;quot;,
    &amp;quot;sd_age__speech_rate&amp;quot;
  ),
  prob_outer = 0.99,
  prob = 0.95
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab3_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While the summary table is useful to get a sense of the model, and the subsequent chart visualizes the coefficients of the model for both the population and group levels, looking at the effect sizes for speech rate per age group is most illustrative.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model_summary &amp;lt;- summary(partial_pool_model)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: There were 278 divergent transitions after warmup. Increasing
## adapt_delta above 0.99 may help. See http://mc-stan.org/misc/
## warnings.html#divergent-transitions-after-warmup
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;effect_estimates &amp;lt;- as_tibble(ranef(partial_pool_model)[[1]]) %&amp;gt;%
  mutate(Estimate.speech_rate_with_fixed = Estimate.speech_rate + model_summary$fixed[2, 1])
  

ggplot(
  data = effect_estimates,
  aes(
    x = c(4, 7, 10),
    y = Estimate.speech_rate_with_fixed
  )
) +
  geom_point() +
  geom_errorbar(
    aes(
      ymin = Estimate.speech_rate_with_fixed - 2 * Est.Error.speech_rate,
      ymax = Estimate.speech_rate_with_fixed + 2 * Est.Error.speech_rate
    )
  ) +
  scale_x_continuous(
    breaks = c(4, 7, 10),
  ) +
  xlab(&amp;quot;Age&amp;quot;) +
  ylab(&amp;quot;Estimated Effect of Speech Rate on Memory (-/+ 2sd)&amp;quot;) +
  geom_label_repel(
    aes(
      label = round(Estimate.speech_rate_with_fixed, 2)
    ),
    nudge_y = 1
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab3_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above chart shows the estimated effect of speech rate on memory by age. We can see that, somewhat surprisingly, age 7 is where the effect of speech rate on memory is greatest while at age 4 it is the lowest.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lab 4 - ANOVA</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-4-anova/</link>
      <pubDate>Tue, 01 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-4-anova/</guid>
      <description>
&lt;script src=&#34;https://djshives.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(papaja)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;question-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Question (1)&lt;/h2&gt;
&lt;div id=&#34;use-r-to-conduct-a-t.test-and-anova-on-the-below-example-data.-then-use-r-to-prove-that-the-results-of-both-analyses-are-the-same.-for-example-prove-that-the-p-values-are-the-same-and-prove-that-the-f-value-and-t-value-are-related.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use R to conduct a t.test and ANOVA on the below example data. Then use R to prove that the results of both analyses are the same. For example, prove that the p-values are the same, and prove that the F-value and T-value are related.&lt;/h3&gt;
&lt;p&gt;Loading in the example data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_data &amp;lt;- tibble(Group = rep(c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;), each = 5),
                       DV = c(2,4,3,5,4,7,6,5,6,7))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running an ANOVA on the example data, saving it to an object, and displaying the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_anova &amp;lt;- aov(DV ~ Group, example_data)
summary(example_anova)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Df Sum Sq Mean Sq F value  Pr(&amp;gt;F)   
## Group        1   16.9    16.9    16.9 0.00339 **
## Residuals    8    8.0     1.0                   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running a two sample t-test on the sample data, saving it to an object, and displaying the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_t_test &amp;lt;- t.test(DV ~ Group, example_data, var.equal = TRUE)
example_t_test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two Sample t-test
## 
## data:  DV by Group
## t = -4.111, df = 8, p-value = 0.003386
## alternative hypothesis: true difference in means between group A and group B is not equal to 0
## 95 percent confidence interval:
##  -4.058445 -1.141555
## sample estimates:
## mean in group A mean in group B 
##             3.6             6.2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;showing-that-the-results-of-both-analyses-are-the-same.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Showing that the results of both analyses are the same.&lt;/h3&gt;
&lt;p&gt;The square of the t-statistic and the F-statistic are the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;round((example_t_test$statistic ^ 2), 5) == round(summary(example_anova)[[1]][1, 4], 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    t 
## TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The p-values for both are the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;round(example_t_test$p.value, 5) == round(summary(example_anova)[[1]][1, 5], 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;question-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Question (2)&lt;/h2&gt;
&lt;div id=&#34;look-at-the-lab-on-anova-that-i-wrote-for-our-undergraduate-statistics-oer-lab-manual-httpscrumplab.github.iostatisticslablab-8-one-way-anova.html.-that-lab-shows-an-example-of-obtaining-data-from-a-published-paper-in-psych-science-where-a-one-factor-anova-was-used-as-a-part-of-the-analysis.-load-the-data-conduct-the-anova-report-a-ggplot-of-the-means-and-use-papaja-to-help-you-write-a-short-results-section-reporting-the-anova-result.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Look at the lab on ANOVA that I wrote for our undergraduate statistics OER lab manual &lt;a href=&#34;https://crumplab.github.io/statisticsLab/lab-8-one-way-anova.html&#34; class=&#34;uri&#34;&gt;https://crumplab.github.io/statisticsLab/lab-8-one-way-anova.html&lt;/a&gt;. That lab shows an example of obtaining data from a published paper in psych science where a one-factor ANOVA was used as a part of the analysis. Load the data, conduct the ANOVA, report a ggplot of the means, and use papaja to help you write a short results section reporting the ANOVA result.&lt;/h3&gt;
&lt;p&gt;Loading in the experimental data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/CrumpLab/statisticsLab/master/data/Jamesetal2015Experiment2.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Creating the factors and levels for “Condition”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data$Condition &amp;lt;- as.factor(data$Condition)

levels(data$Condition) &amp;lt;- c(&amp;quot;Control&amp;quot;, &amp;quot;Reactivation+Tetris&amp;quot;, &amp;quot;Tetris_only&amp;quot;, &amp;quot;Reactivation_only&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-the-means-standard-deviations-and-individual-scores.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Graphing the means, standard deviations, and individual scores.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;descriptive_df &amp;lt;- data %&amp;gt;% 
                    group_by(Condition) %&amp;gt;% 
                    summarise(means= mean(Days_One_to_Seven_Number_of_Intrusions),
                              SEs = sd(Days_One_to_Seven_Number_of_Intrusions)/sqrt(length(Days_One_to_Seven_Number_of_Intrusions)))

ggplot(descriptive_df, aes(x=Condition, y=means)) + 
  geom_bar(stat=&amp;quot;identity&amp;quot;, aes(fill=Condition)) + 
  geom_errorbar(aes(ymin=means-SEs,               
                    ymax=means+SEs), width=.1) +
  geom_point(data=data, aes(x=Condition, y=Days_One_to_Seven_Number_of_Intrusions), alpha=.5)+
  geom_point(alpha=.25)+
  ylab(&amp;quot;Intrusive Memories (Mean for Week)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab4_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Running an ANOVA on the experimental data, saving it to an object, and displaying the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova &amp;lt;- aov(Days_One_to_Seven_Number_of_Intrusions ~ Condition, data)

summary(anova)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
## Condition    3  114.8   38.27   3.795 0.0141 *
## Residuals   68  685.8   10.09                 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reporting-the-result-using-papaja.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reporting the result using papaja.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;apa_output &amp;lt;- apa_print(anova)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main effect of condition was significant, &lt;span class=&#34;math inline&#34;&gt;\(F(3, 68) = 3.79\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mathit{MSE} = 10.09\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p = .014\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\hat{\eta}^2_G = .143\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 5 - ANOVA and Randomization</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-5-anova-randomization/</link>
      <pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-5-anova-randomization/</guid>
      <description>
&lt;script src=&#34;https://djshives.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://djshives.netlify.app/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://djshives.netlify.app/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(kableExtra)

set.seed(1)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;consider-a-design-with-3-groups-and-10-people-per-group.-assume-that-the-dependent-variable-is-assumed-to-be-normally-distributed-and-use-unit-normal-distributions-with-mean-0-and-sd-1-in-your-simulations.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Consider a design with 3 groups, and 10 people per group. Assume that the dependent variable is assumed to be normally distributed, and use unit normal distributions with mean = 0, and sd = 1 in your simulations.&lt;/h2&gt;
&lt;div id=&#34;setting-the-parameters-for-the-data-and-subsequent-simulations.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting the parameters for the data and subsequent simulations.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels &amp;lt;- 3
n_per_level &amp;lt;- 10
n_samples &amp;lt;- 1000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-null-distribution.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating the null distribution.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gen_sim_f &amp;lt;- function(num_levels, num_per_level, num_samples) {
  f_values &amp;lt;- length(num_samples)

  for(i in 1:num_samples) {
    sim_data &amp;lt;- tibble(subject = 1:(num_levels * num_per_level),
                       level = as.factor(rep(1:num_levels, each = num_per_level)),
                       DV = rnorm(num_levels * num_per_level, 0, 1))
    anova_out &amp;lt;- aov(DV ~ level, sim_data)
    f_ &amp;lt;- summary(anova_out)[[1]]$`F value`[1]
    f_values[i] &amp;lt;- f_
    
    f_values_df &amp;lt;- tibble(f_value = f_values,
                          sample = 1:length(f_values))
  }
  return(f_values_df)
}

sim_f_values &amp;lt;- gen_sim_f(levels, n_per_level, n_samples)

ggplot(sim_f_values) +
  geom_histogram(aes(x = f_value), bins = 100) +
  geom_vline(aes(xintercept = 4.737, color = &amp;quot;red&amp;quot;), linetype = &amp;quot;dashed&amp;quot;) +
  annotate(x = 4.737, y = 50, label = &amp;quot;Critical Value = 4.737&amp;quot;, geom = &amp;quot;label&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-function-that-adds-an-effect-to-the-first-level.-this-will-allow-for-the-design-to-produce-an-f-value-that-is-smaller-or-larger-than-the-critical-f-value.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating a function that adds an effect to the first level. This will allow for the design to produce an F-value that is smaller or larger than the critical F-value.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gen_effect_data &amp;lt;- function(num_levels, num_per_level, num_samples, effect_size) {
  
  column_names = c(&amp;quot;subjects&amp;quot;, &amp;quot;IV&amp;quot;, &amp;quot;DV&amp;quot;, &amp;quot;sample&amp;quot;)
  
  total_sim_data &amp;lt;- as_tibble(t(column_names))[0, ]
  
  for(i in 1:num_samples) {
    sim_data &amp;lt;- tibble(subject = 1:(num_levels * num_per_level),
                       level = as.factor(rep(1:num_levels, each = num_per_level)),
                       DV = rnorm(num_levels * num_per_level, 0, 1),
                       sample = i)
    
    sim_data[sim_data$level == 1, ]$DV &amp;lt;- sim_data[sim_data$level == 1, ]$DV + effect_size
    
    total_sim_data &amp;lt;- rbind(total_sim_data, sim_data)
    
  }
  
  total_sim_data &amp;lt;- total_sim_data %&amp;gt;%
    group_by(subject, level) %&amp;gt;%
    summarise(DV = mean(DV))
  
  return(total_sim_data)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(1)&lt;/h2&gt;
&lt;p&gt;Create simulated data for the above design that could be produced by the null hypothesis, and that results in a 𝐹 value that is smaller than the critical value for 𝐹 in this design (assume alpha = .05). Report the ANOVA, and show a ggplot of the means in the simulated data. Furthermore, display the individual data points on top of the means. Would you reject the null hypothesis in this situation, and would you be incorrect or correct in rejecting the null?&lt;/p&gt;
&lt;div id=&#34;creating-simulated-data-with-an-effect-size-applied-to-level-1-of-0.01-and-displaying-the-anova-summary.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating simulated data with an effect size applied to level 1 of 0.01 and displaying the ANOVA summary.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_effect_data &amp;lt;- gen_effect_data(levels, n_per_level, n_samples, 0.01)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.
## Using compatibility `.name_repair`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;subject&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_effect_anova &amp;lt;- aov(DV ~ level, lower_effect_data)

unclass(summary(lower_effect_anova)) %&amp;gt;%
  kbl(digits = 2) %&amp;gt;%
  kable_classic(position = &amp;quot;center&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;kable_wrapper lightable-classic&#34; style=&#34;font-family: &amp;quot;Arial Narrow&amp;quot;, &amp;quot;Source Sans Pro&amp;quot;, sans-serif; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Df
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sum Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Mean Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F value
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pr(&amp;gt;F)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
level
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.36
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.27
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Residuals
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-the-f-value-against-the-null-distribution.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Graphing the F value against the null distribution.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_f_value &amp;lt;- summary(lower_effect_anova)[[1]]$`F value`[1]

ggplot(sim_f_values) +
  geom_histogram(aes(x = f_value), bins = 100) +
  geom_vline(aes(xintercept = 4.737, color = &amp;quot;red&amp;quot;), linetype = &amp;quot;dashed&amp;quot;) +
  annotate(x = 4.737, y = 50, label = &amp;quot;Critical Value = 4.737&amp;quot;, geom = &amp;quot;label&amp;quot;) +
  geom_vline(aes(xintercept = lower_f_value, color = &amp;quot;blue&amp;quot;)) +
  annotate(x = lower_f_value, y = 75, xend = 0, label =  paste0(&amp;quot;Simulated F value = &amp;quot;, round(lower_f_value, 2)), geom = &amp;quot;label&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown aesthetics: xend&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-the-means-of-the-simulated-data-where-the-effect-size-was-0.01.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Graphing the means of the simulated data where the effect size was 0.01.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_effect_data_grouped &amp;lt;- lower_effect_data %&amp;gt;%
  group_by(level) %&amp;gt;%
  summarise(mean_DV = mean(DV),
            SE = sd(DV)/length(DV))

ggplot(lower_effect_data_grouped, aes(x = level, y = mean_DV)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, aes(fill = level)) +
  scale_y_continuous(limits = c(-0.05, 0.05)) +
  geom_errorbar(aes(ymin=mean_DV - SE,
                    ymax=mean_DV + SE), width=.1) + 
  geom_point(data = lower_effect_data, mapping = aes(x = level, y = DV), alpha = 0.5) +
  geom_point(alpha=.25) +
  ylab(&amp;quot;DV&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 4 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I would not reject the null in this situation as the F value calculated from the simulated data is less than the critical value. The parameters of the simulation, however, can produce data that leads to an F value greater than the critical value, but that is unlikely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;section-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(2)&lt;/h2&gt;
&lt;p&gt;Create simulated data for the above design that could be produced by the null hypothesis, and that results in a 𝐹 value that is larger than the critical value for 𝐹 in this design (assume alpha = .05). Report the ANOVA, and show a ggplot of the means in the simulated data. Furthermore, display the individual data points on top of the means. Would you reject the null hypothesis in this situation, and would you be incorrect or correct in rejecting the null?&lt;/p&gt;
&lt;div id=&#34;creating-simulated-data-with-an-effect-size-applied-to-level-1-of-0.035-and-displaying-the-anova-summary.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating simulated data with an effect size applied to level 1 of 0.035 and displaying the ANOVA summary.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;higher_effect_data &amp;lt;- gen_effect_data(levels, n_per_level, n_samples, 0.035)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;subject&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;higher_effect_anova &amp;lt;- aov(DV ~ level, higher_effect_data)

unclass(summary(higher_effect_anova)) %&amp;gt;%
  kbl(digits = 2) %&amp;gt;%
  kable_classic(position = &amp;quot;center&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;kable_wrapper lightable-classic&#34; style=&#34;font-family: &amp;quot;Arial Narrow&amp;quot;, &amp;quot;Source Sans Pro&amp;quot;, sans-serif; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Df
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Sum Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Mean Sq
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
F value
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pr(&amp;gt;F)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
level
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.01
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Residuals
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.02
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-the-f-value-against-the-null-distribution.-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Graphing the F value against the null distribution.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;higher_f_value &amp;lt;- summary(higher_effect_anova)[[1]]$`F value`[1]

ggplot(sim_f_values) +
  geom_histogram(aes(x = f_value), bins = 100) +
  geom_vline(aes(xintercept = 4.737, color = &amp;quot;red&amp;quot;), linetype = &amp;quot;dashed&amp;quot;) +
  annotate(x = 4.737, y = 50, label = &amp;quot;Critical Value = 4.737&amp;quot;, geom = &amp;quot;label&amp;quot;) +
  geom_vline(aes(xintercept = higher_f_value, color = &amp;quot;blue&amp;quot;)) +
  annotate(x = higher_f_value, y = 75, xend = 8.0, label =  paste0(&amp;quot;Simulated F value = &amp;quot;, round(higher_f_value, 2)), geom = &amp;quot;label&amp;quot;) +
  expand_limits(x = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Ignoring unknown aesthetics: xend&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphing-the-means-of-the-simulated-data-where-the-effect-size-was-0.01.-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Graphing the means of the simulated data where the effect size was 0.01.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;higher_effect_data_grouped &amp;lt;- higher_effect_data %&amp;gt;%
  group_by(level) %&amp;gt;%
  summarise(mean_DV = mean(DV),
            SE = sd(DV)/length(DV))

ggplot(higher_effect_data_grouped, aes(x = level, y = mean_DV)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, aes(fill = level)) +
  scale_y_continuous(limits = c(-0.05, 0.05)) +
  geom_errorbar(aes(ymin=mean_DV - SE,
                    ymax=mean_DV + SE), width=.1) + 
  geom_point(data = higher_effect_data, mapping = aes(x = level, y = DV), alpha = 0.5) +
  geom_point(alpha=.25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 2 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I would reject the null in this situation as the F value calculated from the simulated data is greater than the critical value. The parameters of the simulation, however, can produce data that leads to an F value less than the critical value, but that is unlikely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-question&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus Question:&lt;/h2&gt;
&lt;p&gt;In the lab we saw that F-distribution is robust to violations of the assumptions of ANOVA. For example, the simulation of the null based on a bi-modal distribution was very similar to the true F distribution. For this bonus question, show that you can “break” the F-distribution. Specifically, can you run a simulation that samples numbers from a non-normal distribution that does produce a very different looking F-distribution?&lt;/p&gt;
&lt;div id=&#34;breaking-the-f-distribution-by-sampling-data-from-a-weibull-distribution-shape-0.1-scale-1000.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Breaking the F-distribution by sampling data from a Weibull distribution (shape = 0.1, scale = 1000).&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gen_sim_f &amp;lt;- function(num_levels, num_per_level, num_samples) {
  f_values &amp;lt;- length(num_samples)

  for(i in 1:num_samples) {
    sim_data &amp;lt;- tibble(subject = 1:(num_levels * num_per_level),
                       level = as.factor(rep(1:num_levels, each = num_per_level)),
                       DV = rweibull(num_levels * num_per_level, shape = 0.1, scale = 1000))
    anova_out &amp;lt;- aov(DV ~ level, sim_data)
    f_ &amp;lt;- summary(anova_out)[[1]]$`F value`[1]
    f_values[i] &amp;lt;- f_
    
    f_values_df &amp;lt;- tibble(f_value = f_values,
                          sample = 1:length(f_values))
  }
  return(f_values_df)
}

sim_f_values &amp;lt;- gen_sim_f(levels, n_per_level, n_samples)

ggplot(sim_f_values) +
  geom_histogram(aes(x = f_value), bins = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/Lab5_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 6 - Comparisons</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-6-comparisons/</link>
      <pubDate>Sun, 30 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-6-comparisons/</guid>
      <description>


&lt;div id=&#34;section-12.3.3-from-your-textbook-refers-to-the-problem-with-replications-of-a-meaningless-experiment-alpha-and-the-captains-age.-the-issue-here-is-that-if-you-run-an-ineffectual-experiment-enough-times-you-can-always-find-a-significant-result-by-chance.-the-textbook-mentions-that-if-you-repeat-an-experiment-20-times-you-are-guaranteed-to-find-a-significant-result-with-.64-probability-and-the-probability-is-.92-if-you-repeat-the-experiment-50-times.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(1) Section 12.3.3 from your textbook refers to: The problem with replications of a meaningless experiment: ‘alpha and the captain’s age’. The issue here is that if you run an ineffectual experiment enough times you can always find a significant result by chance. The textbook mentions that if you repeat an experiment 20 times, you are guaranteed to find a significant result with .64 probability, and the probability is .92 if you repeat the experiment 50 times.&lt;/h2&gt;
&lt;div id=&#34;a-make-use-of-the-rbinom-function-to-show-you-can-reproduce-both-probabilities.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1a) Make use of the rbinom() function to show you can reproduce both probabilities.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a_20 &amp;lt;- rbinom(10000, 20, 0.05)

hist(a_20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab6_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(a_20[a_20 &amp;gt; 0]) / 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6455&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a_50 &amp;lt;- rbinom(10000, 50, 0.05)

hist(a_50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab6_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(a_50[a_50 &amp;gt; 0]) / 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9291&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;b-if-the-ineffectual-experiment-was-conducted-20-times-and-there-were-four-groups-and-the-experimenter-would-accept-a-significant-result-from-any-of-the-orthogonal-linear-contrasts-what-would-be-the-probability-of-finding-a-significant-result-here&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1b) If the ineffectual experiment was conducted 20 times, and there were four groups, and the experimenter would accept a significant result from any of the orthogonal linear contrasts, what would be the probability of finding a significant result here?&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- replicate(10000, sum(rbinom(20, 3, 0.05)))

length(B[B &amp;gt; 0]) / 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.952&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;consider-that-a-researcher-publishes-a-study-showing-a-significant-effect-p-.-05-but-in-reality-the-researcher-makes-a-type-i-error-and-the-manipulation-did-not-cause-any-difference.-if-many-other-researchers-replicated-the-study-what-kind-of-p-values-would-they-find-use-r-to-create-a-sampling-distribution-of-p-values-that-would-be-expected-in-this-situation.-what-shape-does-this-distribution-have&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(2) Consider that a researcher publishes a study showing a significant effect, p &amp;lt;. 05; but, in reality the researcher makes a type I error, and the manipulation did not cause any difference. If many other researchers replicated the study, what kind of p-values would they find? Use R to create a sampling distribution of p-values that would be expected in this situation. What shape does this distribution have?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_values &amp;lt;- replicate(10000, t.test(rnorm(10, 0, 1), rnorm(10, 0, 1), var.equal = TRUE)$p.value)

hist(p_values)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab6_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-assume-that-the-published-result-reflects-a-true-effect.-specifically-lets-imagine-the-study-had-two-groups-between-subjects-with-20-subjects-in-each-group.-assume-that-scores-for-subjects-are-all-sampled-from-a-normal-distribution-and-that-group-a-has-larger-mean-than-group-b-by-.5-standard-deviations-e.g.-cohens-d-.5.-if-many-other-researchers-replicated-the-study-what-kind-of-p-values-would-they-find-use-r-to-create-a-sampling-distribution-of-p-values-that-would-be-expected-in-this-situation.-what-shape-does-this-distribution-have&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(3) Now assume that the published result reflects a true effect. Specifically, let’s imagine the study had two groups (between-subjects), with 20 subjects in each group. Assume that scores for subjects are all sampled from a normal distribution, and that group A has larger mean than group B by .5 standard deviations (e.g., Cohen’s d = .5). If many other researchers replicated the study, what kind of p-values would they find? Use R to create a sampling distribution of p-values that would be expected in this situation. What shape does this distribution have?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_values &amp;lt;- replicate(10000, t.test(rnorm(20, 0, 1), rnorm(20, 0.5, 1), var.equal = TRUE)$p.value)

hist(p_values)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab6_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 7 - Factorial ANOVA</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-7-factorial-anova/</link>
      <pubDate>Sat, 29 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-7-factorial-anova/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;in-chapter-10-of-crump-et-al.-2018-there-is-a-discussion-of-patterns-of-main-effects-and-interactions-that-can-occur-in-a-2x2-design-which-represents-perhaps-the-simplest-factorial-design.-there-are-8-possible-outcomes-discussed-httpscrumplab.github.iostatisticsmore-on-factorial-designs.htmllooking-at-main-effects-and-interactions.-examples-of-these-8-outcomes-are-shown-in-two-figures-one-with-bar-graphs-and-one-with-line-graphs.-reproduce-either-of-these-figures-using-ggplot2.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(3) In chapter 10 of Crump et al. (2018), there is a discussion of patterns of main effects and interactions that can occur in a 2x2 design, which represents perhaps the simplest factorial design. There are 8 possible outcomes discussed &lt;a href=&#34;https://crumplab.github.io/statistics/more-on-factorial-designs.html#looking-at-main-effects-and-interactions&#34; class=&#34;uri&#34;&gt;https://crumplab.github.io/statistics/more-on-factorial-designs.html#looking-at-main-effects-and-interactions&lt;/a&gt;. Examples of these 8 outcomes are shown in two figures, one with bar graphs, and one with line graphs. Reproduce either of these figures using ggplot2.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pattern1 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(6,6,6,6))

pattern2 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(10,10,5,5))

pattern3 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(10,13,5,2))

pattern4 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(5,10,10,15))

pattern5 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(10,18,5,7))

pattern6 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(10,2,10,2))

pattern7 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(2,12,5,9))

pattern8 &amp;lt;- tibble(IV1 = c(&amp;quot;A&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;B&amp;quot;),
                IV2 = c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;),
                means = c(5,10,10,5))

all &amp;lt;- rbind(pattern1, pattern2, pattern3, pattern4, pattern5, pattern6, pattern7, pattern8)
type &amp;lt;- c(rep(&amp;quot;~1, ~2, ~1x2&amp;quot;,4),
          rep(&amp;quot;1, ~2, ~1x2&amp;quot;,4),
          rep(&amp;quot;1, ~2, 1x2&amp;quot;,4),
          rep(&amp;quot;1, 2, ~1x2&amp;quot;,4),
          rep(&amp;quot;1, 2, 1x2&amp;quot;,4),
          rep(&amp;quot;~1, 2, ~1x2&amp;quot;,4),
          rep(&amp;quot;~1, 2, 1x2&amp;quot;,4),
          rep(&amp;quot;~1, ~2, 1x2&amp;quot;,4))
type&amp;lt;-as.factor(type)

all &amp;lt;- cbind(all,type)

ggplot(all, aes(x=IV1, y=means, group=IV2, fill=IV2))+
  geom_bar(stat=&amp;quot;identity&amp;quot;, position=&amp;quot;dodge&amp;quot;)+
  theme_classic()+
  facet_wrap(~type, nrow=2)+
  theme(legend.position = &amp;quot;top&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab7_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(all, aes(x=IV1, y=means, group=IV2, color=IV2))+
  geom_point()+
  geom_line()+
  theme_classic()+
  facet_wrap(~type, nrow=2)+
  theme(legend.position = &amp;quot;top&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab7_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;in-the-conceptual-section-of-this-lab-we-used-an-r-simulation-to-find-the-family-wise-type-i-error-rate-for-a-simple-factorial-design-with-2-independent-variables.-use-an-r-simulation-to-find-the-family-wise-type-i-error-rate-for-a-factorial-design-with-3-independent-variables.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(4) In the conceptual section of this lab we used an R simulation to find the family-wise type I error rate for a simple factorial design with 2 independent variables. Use an R simulation to find the family-wise type I error rate for a factorial design with 3 independent variables.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulation &amp;lt;- rbinom(10000,7,.05)
length(simulation[simulation &amp;gt; 0])/10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2995&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;simulation_save &amp;lt;- tibble()

for(i in 1:10000){
  n &amp;lt;- 12
  factorial_data &amp;lt;- tibble(A = factor(rep(c(&amp;quot;L1&amp;quot;,&amp;quot;L2&amp;quot;), each = n)),
                         B = factor(rep(rep(c(&amp;quot;L1&amp;quot;,&amp;quot;L2&amp;quot;), each = n/2),2)),
                         C = factor(rep(c(&amp;quot;L1&amp;quot;,&amp;quot;L2&amp;quot;), n)),
                         DV = rnorm(n*2,0,1))

  output &amp;lt;- summary(aov(DV ~ A*B*C, data = factorial_data))

  simulation_tibble &amp;lt;- tibble(p_values = output[[1]]$`Pr(&amp;gt;F)`[1:7],
                       effect = c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;C&amp;quot;,&amp;quot;AxB&amp;quot;,&amp;quot;AxC&amp;quot;,&amp;quot;BxC&amp;quot;,&amp;quot;AxBxC&amp;quot;),
                       simulation = rep(i,7))

  simulation_save &amp;lt;-rbind(simulation_save, simulation_tibble)
}

type_I_errors &amp;lt;- simulation_save %&amp;gt;%
  filter(p_values &amp;lt; .05) %&amp;gt;%
  group_by(simulation) %&amp;gt;%
  count()

dim(type_I_errors)[1]/10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2815&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 8 - Contrast Analyses</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-8-contrast-analyses/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-8-contrast-analyses/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(usefun)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;consider-a-2x2-design.-assume-the-dv-is-measured-from-a-normal-distribution-with-mean-0-and-standard-deviation-1.-assume-that-the-main-effect-of-a-causes-a-total-shift-of-.5-standard-deviations-of-the-mean-between-the-levels.-assume-that-level-1-of-b-is-a-control-where-you-expect-to-measure-the-standard-effect-of-a.-assume-that-level-2-of-b-is-an-experimental-factor-intended-to-reduce-the-effect-of-a-by-.25-standard-deviations.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(1) Consider a 2x2 design. Assume the DV is measured from a normal distribution with mean 0, and standard deviation 1. Assume that the main effect of A causes a total shift of .5 standard deviations of the mean between the levels. Assume that level 1 of B is a control, where you expect to measure the standard effect of A. Assume that level 2 of B is an experimental factor intended to reduce the effect of A by .25 standard deviations.&lt;/h2&gt;
&lt;div id=&#34;a-create-a-ggplot2-figure-that-depicts-the-expected-results-from-this-design.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1a) Create a ggplot2 figure that depicts the expected results from this design.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grand_mean &amp;lt;- 0
A &amp;lt;- c(0,.5)
B &amp;lt;- c(0,0)
AB &amp;lt;- c(0,0,0,-.25)

model_data &amp;lt;- tibble()

for(i in 1:length(A)){
  for(j in 1:length(B)){
    IVA &amp;lt;- i 
    IVB &amp;lt;- j
    DV &amp;lt;- grand_mean + A[i] + B[j] + AB[(i-1) * length(B) + j]
    sc_GM &amp;lt;- grand_mean
    sc_A &amp;lt;- A[i]
    sc_B &amp;lt;- B[j]
    sc_AB &amp;lt;- AB[(i-1) * length(B) + j] 
    row_entry &amp;lt;- tibble(IVA,IVB,DV,
                        sc_GM,sc_A,sc_B,sc_AB)
    model_data &amp;lt;- rbind(model_data,row_entry)
  }
}

knitr::kable(model_data)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;IVA&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;IVB&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;DV&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sc_GM&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sc_A&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sc_B&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;sc_AB&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bar_graph &amp;lt;- ggplot(model_data, 
                    aes(y=DV,
                        x=as.factor(IVA),
                        fill=as.factor(IVB))) + 
  geom_bar(stat=&amp;#39;identity&amp;#39;, position=&amp;#39;dodge&amp;#39;)

line_graph &amp;lt;- ggplot(model_data, 
                     aes(y=DV,
                         x=IVA,
                         linetype=as.factor(IVB))) + 
  geom_line() + 
  geom_point()

bar_graph&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab8_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;line_graph&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab8_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;b-how-many-subjects-are-needed-to-detect-the-main-effect-of-a-with-power-.8&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1b) How many subjects are needed to detect the main effect of A with power = .8?&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;power_function &amp;lt;- function(num_subjects, effect) {
  
  p_value &amp;lt;- c()
  
  effect_num = c()
  
  if(effect == &amp;quot;A&amp;quot;) {
    effect_num = 1
  } else if(effect == &amp;quot;B&amp;quot;) {
    effect_num = 2
  } else if(effect == &amp;quot;AB&amp;quot;) {
    effect_num =3
  }

  for(i in 1:1000){
    
    simulation_df &amp;lt;- tibble(
      IVA = rep(rep(c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;), each = 2), num_subjects),
      IVB = rep(rep(c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;), 2), num_subjects),
      DV = rnorm(4 * num_subjects, c(0,0,.5,.25), 1)
    )
    aov_results &amp;lt;- summary(aov(DV ~ IVA * IVB, simulation_df))
    p_value[i] &amp;lt;- aov_results[[1]]$`Pr(&amp;gt;F)`[effect_num]
  }
  
  length(p_value[p_value &amp;lt; 0.05]) / 1000
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- c(seq(50, 60))


for(i in n) {
  print(i)
  print(power_function(i, &amp;quot;A&amp;quot;))
  print_empty_line()
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 50
## [1] 0.751
## 
## [1] 51
## [1] 0.766
## 
## [1] 52
## [1] 0.773
## 
## [1] 53
## [1] 0.79
## 
## [1] 54
## [1] 0.789
## 
## [1] 55
## [1] 0.789
## 
## [1] 56
## [1] 0.801
## 
## [1] 57
## [1] 0.813
## 
## [1] 58
## [1] 0.801
## 
## [1] 59
## [1] 0.8
## 
## [1] 60
## [1] 0.842&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;c-how-many-subjects-are-needed-to-detect-the-interaction-effect-with-power-.8&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;(1c) How many subjects are needed to detect the interaction effect with power = .8?&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- c(400, 425, 450, 475, 500, 525, 550, 575, 600)


for(i in n) {
  print(i)
  print(power_function(i, &amp;quot;AB&amp;quot;))
  print_empty_line()
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 400
## [1] 0.725
## 
## [1] 425
## [1] 0.733
## 
## [1] 450
## [1] 0.747
## 
## [1] 475
## [1] 0.784
## 
## [1] 500
## [1] 0.787
## 
## [1] 525
## [1] 0.821
## 
## [1] 550
## [1] 0.835
## 
## [1] 575
## [1] 0.853
## 
## [1] 600
## [1] 0.858&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 9 - RM ANOVA</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-9-rm-anova/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-9-rm-anova/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(foreach)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;create-an-r-script-that-can-generate-simulated-data-for-the-following-repeated-measures-design.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(1) Create an R script that can generate simulated data for the following repeated measures design.&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;The dependent variable is assumed to come from a normal distribution with mean = 0 and standard deviation = 1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There is one repeated measures factor with 5 levels (Down1, Down2, Control, Up1, Up2). The control group is assumed to have no effect. The Down1 and Down2 levels shift the mean down by 1 and 2 standard deviations, respectively. The Up1 and Up2 levels shift the mean up by 1 and 2 standard deviations, respectively.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There are 6 subjects in the experiment, and they are each measured once in each condition. The 6 subjects are assumed to be different from one another (e.g., they will have different baseline means in the control condition), but they will all be influenced by the IV in the exact same way (e.g., no interaction).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;make_subject_data &amp;lt;- function(num_subjects, level_names, baseline_mean, baseline_sd, variation_vector) {
  
  simulated_data &amp;lt;- tibble(
    subject = as.factor(rep(1:num_subjects, each = length(level_names))),
    IV = as.factor(rep(level_names, num_subjects)),
    DV = rnorm(num_subjects * length(level_names), base_mean + var_vector, base_sd)
  )
  
  return(simulated_data)
  
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;norm_function &amp;lt;- function(means_vector, sds_vector) {
  norm_vector &amp;lt;- c()
  
  foreach(i = means_vector, j= sds_vector) %do% {
    norm_vector &amp;lt;- append(norm_vector, rnorm(1, i, j))
  }
  
  return(norm_vector)
}

make_subject_data_shift &amp;lt;- function(num_subjects, level_names, baseline_mean, baseline_sd, variation_vector, shift_means, shift_sd, randomize = FALSE) {
  
  if(randomize == TRUE) {
    shift_means &amp;lt;- sample(shift_means)
    shift_sd &amp;lt;- sample(shift_sd)
  }
  
  simulated_data &amp;lt;- tibble(
    subject = as.factor(rep(1:num_subjects, each = length(level_names))),
    IV = as.factor(rep(level_names, num_subjects)),
    DV = rnorm(num_subjects * length(level_names), base_mean + var_vector, base_sd),
    shift = as.vector(t(replicate(length(level_names), sapply(shift_means, norm_function, sds_vector = shift_sd)))),
    DV_shift = DV + shift
  )
  return(simulated_data)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;run-a-simulation-to-determine-the-proportion-of-experiments-that-would-return-a-significant-result-for-the-above-design.-assume-that-the-effect-of-the-levels-of-the-iv-are-increments-of-.1-of-a-standard-deviation-rather-than-increments-of-1-as-in-the-above-design.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(2) Run a simulation to determine the proportion of experiments that would return a significant result for the above design. Assume that the effect of the levels of the IV are increments of .1 of a standard deviation, rather than increments of 1 as in the above design.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;num_subs &amp;lt;- 6
lev_nam &amp;lt;- c(&amp;quot;Down2&amp;quot;, &amp;quot;Down1&amp;quot;, &amp;quot;Control&amp;quot;, &amp;quot;Up1&amp;quot;, &amp;quot;Up2&amp;quot;)
base_mean &amp;lt;- 0
base_sd &amp;lt;- 1
var_vector &amp;lt;- c(-0.2, -0.1, 0, 0.1, 0.2)

one_factor_rm_sim &amp;lt;- make_subject_data(num_subs, lev_nam, base_mean, base_sd, var_vector)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova_summary &amp;lt;- summary(aov(DV ~ IV + Error(subject), data = one_factor_rm_sim))

anova_summary[[2]][[1]]$`Pr(&amp;gt;F)`[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1399453&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_values &amp;lt;- c()

for(i in 1:1000) {
  one_factor &amp;lt;- make_subject_data(num_subs, lev_nam, base_mean, base_sd, var_vector)
  anova_summary &amp;lt;- summary(aov(DV ~ IV + Error(subject), data = one_factor))
  p_values &amp;lt;- append(p_values, anova_summary[[2]][[1]]$`Pr(&amp;gt;F)`[1])
}

hist(p_values)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab9_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;demonstrate-that-the-godden-and-baddeley-example-data-from-the-textbook-19.5-which-used-a-2x2-repeated-measures-design-can-be-be-analyzed-with-one-sample-t-tests-to-return-the-same-results.-specifically-show-the-one-sample-t-tests-for-each-main-effect-and-the-interaction.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(3) Demonstrate that the Godden and Baddeley example data from the textbook (19.5), which used a 2x2 repeated measures design, can be be analyzed with one-sample t-tests to return the same results. Specifically, show the one-sample t-tests for each main effect and the interaction.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_gb &amp;lt;- tribble(~subjects,~learning_place,~testing_place,~recall,
        &amp;quot;s1&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;On Land&amp;quot;,34,
        &amp;quot;s2&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;On Land&amp;quot;,37,
        &amp;quot;s3&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;On Land&amp;quot;,27,
        &amp;quot;s4&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;On Land&amp;quot;,43,
        &amp;quot;s5&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;On Land&amp;quot;,44,
        &amp;quot;s1&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;Under Sea&amp;quot;,18,
        &amp;quot;s2&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;Under Sea&amp;quot;,21,
        &amp;quot;s3&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;Under Sea&amp;quot;,25,
        &amp;quot;s4&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;Under Sea&amp;quot;,37,
        &amp;quot;s5&amp;quot;,&amp;quot;On Land&amp;quot;,&amp;quot;Under Sea&amp;quot;,34,
        &amp;quot;s1&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;On Land&amp;quot;,14,
        &amp;quot;s2&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;On Land&amp;quot;,21,
        &amp;quot;s3&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;On Land&amp;quot;,31,
        &amp;quot;s4&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;On Land&amp;quot;,27,
        &amp;quot;s5&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;On Land&amp;quot;,32,
        &amp;quot;s1&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;Under Sea&amp;quot;,22,
        &amp;quot;s2&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;Under Sea&amp;quot;,25,
        &amp;quot;s3&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;Under Sea&amp;quot;,33,
        &amp;quot;s4&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;Under Sea&amp;quot;,33,
        &amp;quot;s5&amp;quot;,&amp;quot;Under Sea&amp;quot;,&amp;quot;Under Sea&amp;quot;,42
        )

df_gb &amp;lt;- df_gb %&amp;gt;%
  mutate(subjects = as.factor(subjects),
         learning_place = as.factor(learning_place),
         testing_place = as.factor(testing_place))

aov_out &amp;lt;- aov(recall ~ learning_place*testing_place + Error(subjects/(learning_place*testing_place)), df_gb)

summary(aov_out)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: subjects
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Residuals  4    680     170               
## 
## Error: subjects:learning_place
##                Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## learning_place  1     80      80       2   0.23
## Residuals       4    160      40               
## 
## Error: subjects:testing_place
##               Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## testing_place  1     20      20     2.5  0.189
## Residuals      4     32       8               
## 
## Error: subjects:learning_place:testing_place
##                              Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
## learning_place:testing_place  1    320     320      20 0.0111 *
## Residuals                     4     64      16                 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df_gb, aes(x=testing_place, 
                  y=recall,
                  shape=learning_place,
                  group=learning_place))+
  geom_point(stat=&amp;quot;summary&amp;quot;,fun=&amp;quot;mean&amp;quot;)+
  geom_line(stat=&amp;quot;summary&amp;quot;,fun=&amp;quot;mean&amp;quot;)+
  theme_classic(base_size=12)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://djshives.netlify.app/courses/PSYC7709G/lessons/Lab9_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;learning_place_means &amp;lt;- df_gb %&amp;gt;%
  group_by(subjects,learning_place) %&amp;gt;%
  summarize(mean_recall = mean(recall))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;subjects&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(mean_recall ~ learning_place, paired=TRUE, data=learning_place_means)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Paired t-test
## 
## data:  mean_recall by learning_place
## t = 1.4142, df = 4, p-value = 0.2302
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -3.852973 11.852973
## sample estimates:
## mean of the differences 
##                       4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;learning_land &amp;lt;- learning_place_means %&amp;gt;%
  filter(learning_place == &amp;quot;On Land&amp;quot;) %&amp;gt;%
  select(mean_recall)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `subjects`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;learning_sea &amp;lt;- learning_place_means %&amp;gt;%
  filter(learning_place == &amp;quot;Under Sea&amp;quot;) %&amp;gt;%
  select(mean_recall)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `subjects`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(learning_land$mean_recall - learning_sea$mean_recall, mu=0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  learning_land$mean_recall - learning_sea$mean_recall
## t = 1.4142, df = 4, p-value = 0.2302
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -3.852973 11.852973
## sample estimates:
## mean of x 
##         4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testing_place_means &amp;lt;- df_gb %&amp;gt;%
  group_by(subjects,testing_place) %&amp;gt;%
  summarize(mean_recall = mean(recall))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` has grouped output by &amp;#39;subjects&amp;#39;. You can override using the
## `.groups` argument.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(mean_recall ~ testing_place, paired=TRUE, data=testing_place_means)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Paired t-test
## 
## data:  mean_recall by testing_place
## t = 1.5811, df = 4, p-value = 0.189
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.511956  5.511956
## sample estimates:
## mean of the differences 
##                       2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testing_land &amp;lt;- testing_place_means %&amp;gt;%
  filter(testing_place == &amp;quot;On Land&amp;quot;) %&amp;gt;%
  select(mean_recall)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `subjects`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testing_sea &amp;lt;- testing_place_means %&amp;gt;%
  filter(testing_place == &amp;quot;Under Sea&amp;quot;) %&amp;gt;%
  select(mean_recall)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Adding missing grouping variables: `subjects`&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(testing_land$mean_recall - testing_sea$mean_recall, mu=0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  testing_land$mean_recall - testing_sea$mean_recall
## t = 1.5811, df = 4, p-value = 0.189
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -1.511956  5.511956
## sample estimates:
## mean of x 
##         2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;land_land &amp;lt;- df_gb %&amp;gt;%
  filter(learning_place == &amp;quot;On Land&amp;quot;,
         testing_place == &amp;quot;On Land&amp;quot;) %&amp;gt;%
  pull(recall)

land_sea &amp;lt;- df_gb %&amp;gt;%
  filter(learning_place == &amp;quot;On Land&amp;quot;,
         testing_place == &amp;quot;Under Sea&amp;quot;) %&amp;gt;%
  pull(recall)

sea_land &amp;lt;- df_gb %&amp;gt;%
  filter(learning_place == &amp;quot;Under Sea&amp;quot;,
         testing_place == &amp;quot;On Land&amp;quot;) %&amp;gt;%
  pull(recall)

sea_sea &amp;lt;- df_gb %&amp;gt;%
  filter(learning_place == &amp;quot;Under Sea&amp;quot;,
         testing_place == &amp;quot;Under Sea&amp;quot;) %&amp;gt;%
  pull(recall)

t.test((land_land - land_sea) - (sea_land - sea_sea), mu=0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  (land_land - land_sea) - (sea_land - sea_sea)
## t = 4.4721, df = 4, p-value = 0.01106
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##   6.066688 25.933312
## sample estimates:
## mean of x 
##        16&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lab 10 - Nested Designs</title>
      <link>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-10-nested-designs/</link>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://djshives.netlify.app/courses/psyc7709g/lessons/lab-10-nested-designs/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;from-chapter-20-reproduce-the-bat-and-hat-example-20.2-in-r.-your-code-should-represent-the-data-in-long-form-conduct-the-anova-and-report-the-anova-table.-you-will-know-if-you-did-it-correctly-if-you-can-reproduce-the-anova-table-from-the-textbook.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(1) From Chapter 20, reproduce the bat and hat example (20.2) in R. Your code should represent the data in long-form, conduct the ANOVA, and report the ANOVA table. You will know if you did it correctly if you can reproduce the ANOVA table from the textbook.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subject &amp;lt;- c(rep(c(&amp;quot;s1&amp;quot;,&amp;quot;s2&amp;quot;,&amp;quot;s3&amp;quot;,&amp;quot;s4&amp;quot;,&amp;quot;s5&amp;quot;),2),
             rep(c(&amp;quot;s6&amp;quot;,&amp;quot;s7&amp;quot;,&amp;quot;s8&amp;quot;,&amp;quot;s9&amp;quot;,&amp;quot;s10&amp;quot;),2))
phon_sim &amp;lt;- rep(rep(c(&amp;quot;b1&amp;quot;,&amp;quot;b2&amp;quot;), each=5),2)
age &amp;lt;- rep(c(&amp;quot;a1&amp;quot;,&amp;quot;a2&amp;quot;), each=10)
correct &amp;lt;- c(15,23,12,16,14,
                 13,19,10,16,12,
                 39,31,40,32,38,
                 29,15,30,26,30)

df_bh &amp;lt;- tibble(subject,
                       phon_sim,
                       age,
                       correct)

# run ANOVA
aov_output &amp;lt;- aov(correct ~ phon_sim*age + Error(subject/phon_sim), data = df_bh)

summary(aov_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: subject
##           Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
## age        1   1280    1280      32 0.000478 ***
## Residuals  8    320      40                     
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: subject:phon_sim
##              Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
## phon_sim      1    180     180      45 0.000151 ***
## phon_sim:age  1     80      80      20 0.002077 ** 
## Residuals     8     32       4                     
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;from-chapter-21-reproduce-the-phonological-similarity-example-21.2.1-in-r.-your-code-should-represent-the-data-in-long-form-conduct-the-anova-and-report-the-anova-table.-you-will-know-if-you-did-it-correctly-if-you-can-reproduce-the-anova-table-from-the-textbook.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;(2) From Chapter 21, reproduce the phonological similarity example (21.2.1) in R. Your code should represent the data in long-form, conduct the ANOVA, and report the ANOVA table. You will know if you did it correctly if you can reproduce the ANOVA table from the textbook.&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subject &amp;lt;- rep(c(&amp;quot;s1&amp;quot;,&amp;quot;s2&amp;quot;,&amp;quot;s3&amp;quot;,&amp;quot;s4&amp;quot;), each=10)
typ_b &amp;lt;- rep(rep(c(&amp;quot;b1&amp;quot;,&amp;quot;b2&amp;quot;), each=5),4)
faces_a &amp;lt;- rep(c(&amp;quot;a1&amp;quot;,&amp;quot;a2&amp;quot;,&amp;quot;a3&amp;quot;,&amp;quot;a4&amp;quot;,&amp;quot;a5&amp;quot;),8)
centiseconds &amp;lt;- c(20,22,25,24,19,37,37,43,48,45,
                   9,8,21,21,21,34,35,35,37,39,
                   18,20,18,21,33,35,39,39,37,40,
                   5,14,16,22,23,38,49,51,50,52)

df_face &amp;lt;-  tibble(subject,
                     typ_b,
                     faces_a,
                     centiseconds)

aov_output &amp;lt;- aov(centiseconds  ~ typ_b + (faces_a%in%typ_b) +
                       Error(subject + subject:faces_a + subject:typ_b),
               data = df_face)

summary(aov_output)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: subject
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Residuals  3    240      80               
## 
## Error: subject:faces_a
##               Df Sum Sq Mean Sq F value  Pr(&amp;gt;F)   
## typ_b:faces_a  4    460  115.00   7.263 0.00327 **
## Residuals     12    190   15.83                   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: subject:typ_b
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)   
## typ_b      1   4840    4840   40.33 0.0079 **
## Residuals  3    360     120                  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Error: Within
##               Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## typ_b:faces_a  4     20    5.00   0.353  0.837
## Residuals     12    170   14.17&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
